{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb2cf99",
   "metadata": {},
   "source": [
    "# Tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dd66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e954a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "n_layers = 1\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea4246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "torch.Size([1, 1, 10]) torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# initialize hidden state of each cells\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "print(inp.shape)\n",
    "print(hidden_state.shape, cell_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbda47d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([1, 3, 10])\n",
      "Hidden:  (tensor([[[-8.4851e-02, -8.7748e-02,  6.2854e-02, -1.5089e-01,  7.9291e-05,\n",
      "           1.6117e-01,  1.5947e-01,  1.4106e-01,  1.1534e-01,  1.3942e-01]]],\n",
      "       grad_fn=<StackBackward>), tensor([[[-2.1368e-01, -1.8903e-01,  1.4674e-01, -3.4706e-01,  2.1826e-04,\n",
      "           3.3946e-01,  3.7381e-01,  2.4257e-01,  3.2680e-01,  2.7158e-01]]],\n",
      "       grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "# feed the input and hidden states and see what we’ll get back from it.\n",
    "out, hidden = lstm_layer(inp, hidden)\n",
    "\n",
    "print(\"Output shape: \", out.shape)\n",
    "print(\"Hidden: \", hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c0e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the last output\n",
    "out = out.squeeze()[-1, :]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab44ab",
   "metadata": {},
   "source": [
    "# Real implementation: Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda01a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac2e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.26203380e+07  6.70000000e+01 ...  1.10558328e+00\n",
      "   1.34003885e+00  2.54199820e+00]\n",
      " [ 1.00000000e+00  1.26203380e+07  6.70000000e+01 ...  1.10344075e+00\n",
      "   1.33781144e+00  4.38892897e+00]\n",
      " [ 1.00000000e+00  1.26203380e+07  6.70000000e+01 ...  1.10408973e+00\n",
      "   1.33848613e+00  3.85266160e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  1.26203380e+07  6.70000000e+01 ...  1.10930283e+00\n",
      "   1.34390580e+00 -7.64054656e-01]\n",
      " [ 1.00000000e+00  1.26203380e+07  6.70000000e+01 ...  1.10891630e+00\n",
      "   1.34350395e+00 -3.83384113e-01]\n",
      " [ 1.00000000e+00  1.26203380e+07  6.70000000e+01 ...  1.10956530e+00\n",
      "   1.34417866e+00 -9.91830116e-01]]\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../phm_etching_01M01-02/M02_Groups_same_length/TotalFault_1_Flowcoolleak_Lot_runnum_9741-12620338.csv\"\n",
    "\n",
    "data_import = pd.read_csv(dir_path, encoding=\"utf8\")\n",
    "    \n",
    "data_import.drop(columns=['time', 'Tool', 'Lot', 'TTF_FlowCool Pressure Dropped Below Limit',\n",
    "       'TTF_Flowcool Pressure Too High Check Flowcool Pump', 'TTF_Flowcool leak', 'Lot-runnum'],\n",
    "                     inplace=True)\n",
    "\n",
    "print(data_import.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a710b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5013/5013 [00:39<00:00, 127.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5013, 1005, 21)\n",
      "(5013, 1005, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# TotalFault_5_FlowCoolPressureDroppedBelowLimit-Flowcoolleak-FlowCoolPressureDroppedBelowLimit-FlowCoolPressureDroppedBelowLimit-FlowCoolPressureDroppedBelowLimit_Lot_runnum_9295-10815254\n",
    "\n",
    "dir_path = \"../phm_etching_01M01-02/M02_Groups_same_length/\"\n",
    "shuffle_indexes = [i for i in range(len(os.listdir(dir_path)))]\n",
    "np.random.shuffle(shuffle_indexes)\n",
    "\n",
    "data_x = np.zeros((len(os.listdir(dir_path)), 1005, 21))\n",
    "data_y = np.zeros((len(os.listdir(dir_path)), 1005, 3))\n",
    "\n",
    "# fault detection usage\n",
    "# data_y = pd.DataFrame({\n",
    "#     \"Healthy\": [0 for i in range(len(os.listdir(dir_path)))],\n",
    "#     \"FlowCoolPressureDroppedBelowLimit\": [0 for i in range(len(os.listdir(dir_path)))],\n",
    "#     \"FlowcoolPressureTooHighCheckFlowcoolPump\": [0 for i in range(len(os.listdir(dir_path)))],\n",
    "#     \"Flowcoolleak\": [0 for i in range(len(os.listdir(dir_path)))]\n",
    "# })\n",
    "\n",
    "for fileIndex, file in enumerate(tqdm(os.listdir(dir_path))):\n",
    "    \n",
    "    fault_type_list = list(set(file.split(\"_\")[2].split(\"-\")))\n",
    "    lot_runnum = file.split(\"_\")[5].split(\".\")[0]\n",
    "    \n",
    "    data_import = pd.read_csv(dir_path + file, encoding=\"utf8\")\n",
    "    \n",
    "    data_y[shuffle_indexes[fileIndex]] = data_import[['TTF_FlowCool Pressure Dropped Below Limit',\n",
    "       'TTF_Flowcool Pressure Too High Check Flowcool Pump', 'TTF_Flowcool leak']].to_numpy()\n",
    "    \n",
    "    data_import.drop(columns=['time', 'Tool', 'Lot', 'TTF_FlowCool Pressure Dropped Below Limit',\n",
    "       'TTF_Flowcool Pressure Too High Check Flowcool Pump', 'TTF_Flowcool leak', 'Lot-runnum'],\n",
    "                     inplace=True)\n",
    "\n",
    "     # rearrage value range into between -1 and 1\n",
    "#     scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#     scaler.fit(data_import.to_numpy())\n",
    "    \n",
    "    data_x[shuffle_indexes[fileIndex]] = data_import.to_numpy()\n",
    "    \n",
    "    # fault_detection usage\n",
    "#     for faultType in [\"Healthy\", \"FlowCoolPressureDroppedBelowLimit\",\n",
    "#                       \"FlowcoolPressureTooHighCheckFlowcoolPump\", \"Flowcoolleak\"]:\n",
    "#         if faultType in fault_type_list:\n",
    "#             data_y.loc[shuffle_indexes[fileIndex], faultType] = 1\n",
    "        \n",
    "# fault detection usage\n",
    "# data_y = data_y.to_numpy()\n",
    "        \n",
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e420e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3509, 1005, 21) (1003, 1005, 21) (501, 1005, 21)\n",
      "(3509, 1005, 3) (1003, 1005, 3) (501, 1005, 3)\n"
     ]
    }
   ],
   "source": [
    "# split for training, validation, testing\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.2\n",
    "testing_ratio = 0.1\n",
    "\n",
    "train_indice = int(np.around(len(data_x) * training_ratio, 0))\n",
    "validation_indice = int(np.around(len(data_x) * training_ratio, 0)) +\\\n",
    "int(np.around(len(data_x) * validation_ratio, 0))\n",
    "\n",
    "x_train = data_x[:train_indice]\n",
    "y_train = data_y[:train_indice]\n",
    "x_validation = data_x[train_indice:validation_indice]\n",
    "y_validation = data_y[train_indice:validation_indice]\n",
    "x_test = data_x[validation_indice:]\n",
    "y_test = data_y[validation_indice:]\n",
    "\n",
    "print(x_train.shape, x_validation.shape, x_test.shape)\n",
    "print(y_train.shape, y_validation.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fbbe4",
   "metadata": {},
   "source": [
    "# Activate CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70dae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(is_cuda)\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19391590",
   "metadata": {},
   "source": [
    "# LSTM Modeling\n",
    "\n",
    "#### code reference: \n",
    "  * https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=vIWvJCpOVmwU\n",
    "  * https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e233d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c43a7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor dataset by pytorch\n",
    "data_x = Variable(torch.Tensor(data_x))\n",
    "data_y = Variable(torch.Tensor(data_y))\n",
    "\n",
    "trainX = Variable(torch.Tensor(x_train))\n",
    "trainY = Variable(torch.Tensor(y_train))\n",
    "\n",
    "validX = Variable(torch.Tensor(x_validation))\n",
    "validY = Variable(torch.Tensor(y_validation))\n",
    "\n",
    "testX = Variable(torch.Tensor(x_test))\n",
    "testY = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4efe78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba94986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([3509, 1005, 3])) that is different to the input size (torch.Size([3509, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3509) must match the size of tensor b (1005) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5062a69f5f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# obtain the loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2926\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2928\u001b[1;33m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2929\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3509) must match the size of tensor b (1005) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 21\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60541a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8884a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb687cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b4b042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, input_size, seq_length, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm_model = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        '''\n",
    "        Inputs: input, (h_0, c_0)\n",
    "        \n",
    "        h_0 of shape (num_layers * num_directions, batch, hidden_size): \n",
    "        tensor containing the initial hidden state for each element in the batch. \n",
    "        If the LSTM is bidirectional, num_directions should be 2, else it should be 1. \n",
    "        If proj_size > 0 was specified, the shape has to be (num_layers * num_directions, \n",
    "        batch, proj_size).\n",
    "        \n",
    "        c_0 of shape (num_layers * num_directions, batch, hidden_size): \n",
    "        tensor containing the initial cell state for each element in the batch.\n",
    "        '''\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x_input.size(0), self.hidden_size))\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x_input.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        '''\n",
    "        Outputs: output, (h_n, c_n)\n",
    "        \n",
    "        output of shape (seq_len, batch, num_directions * hidden_size): \n",
    "        tensor containing the output features (h_t) from the last layer of the LSTM, for each t. \n",
    "        If a torch.nn.utils.rnn.PackedSequence has been given as the input, \n",
    "        the output will also be a packed sequence. If proj_size > 0 was specified, \n",
    "        output shape will be (seq_len, batch, num_directions * proj_size).\n",
    "        For the unpacked case, the directions can be separated using \n",
    "        output.view(seq_len, batch, num_directions, hidden_size), \n",
    "        with forward and backward being direction 0 and 1 respectively. \n",
    "        Similarly, the directions can be separated in the packed case.\n",
    "        \n",
    "        h_n of shape (num_layers * num_directions, batch, hidden_size): \n",
    "        tensor containing the hidden state for t = seq_len. \n",
    "        If proj_size > 0 was specified, h_n shape will be \n",
    "        (num_layers * num_directions, batch, proj_size).\n",
    "        Like output, the layers can be separated using \n",
    "        h_n.view(num_layers, num_directions, batch, hidden_size) and similarly for c_n.\n",
    "        \n",
    "        c_n of shape (num_layers * num_directions, batch, hidden_size): \n",
    "        tensor containing the cell state for t = seq_len.\n",
    "        '''\n",
    "        ula, (h_out, _) = self.lstm_model(x_input, (h_0, c_0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a727b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e8b0cd7b1a30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# initialize optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-4844c001930f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_input)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minitial\u001b[0m \u001b[0mcell\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         '''\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mh_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# model configurations\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 21\n",
    "seq_length = 1005\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "\n",
    "lstm = LSTM(num_classes=num_classes, input_size=input_size, hidden_size=hidden_size,\n",
    "           num_layers=num_layers, seq_length=seq_length)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# train model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(x_train)\n",
    "    \n",
    "    # initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain loss and do back propagation\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch:\", str(epoch), \"Loss:\", loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1503ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eaf123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a2ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a03f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
