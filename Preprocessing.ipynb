{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8ddc4e",
   "metadata": {},
   "source": [
    "# Merging train data and ttf data & split by Lot_runnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee567a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01313ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data M01\n",
    "# data_M02_train = pd.read_csv(\"../phm_etching_01M01-02/01_M01_DC_train.csv\",\n",
    "#                             encoding=\"utf8\")\n",
    "\n",
    "# data_M02_ttf = pd.read_csv(\"../phm_etching_01M01-02/01_M01_DC_train_ttf.csv\",\n",
    "#                             encoding=\"utf8\")\n",
    "\n",
    "# data M02\n",
    "data_M02_train = pd.read_csv(\"../phm_etching_01M01-02/01_M02_DC_train.csv\",\n",
    "                            encoding=\"utf8\")\n",
    "\n",
    "data_M02_ttf = pd.read_csv(\"../phm_etching_01M01-02/01_M02_DC_train_ttf.csv\",\n",
    "                            encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00deede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5110542 5110542 5110317\n",
      "Index(['time', 'Tool', 'stage', 'Lot', 'runnum', 'recipe', 'recipe_step',\n",
      "       'IONGAUGEPRESSURE', 'ETCHBEAMVOLTAGE', 'ETCHBEAMCURRENT',\n",
      "       'ETCHSUPPRESSORVOLTAGE', 'ETCHSUPPRESSORCURRENT', 'FLOWCOOLFLOWRATE',\n",
      "       'FLOWCOOLPRESSURE', 'ETCHGASCHANNEL1READBACK', 'ETCHPBNGASREADBACK',\n",
      "       'FIXTURETILTANGLE', 'ROTATIONSPEED', 'ACTUALROTATIONANGLE',\n",
      "       'FIXTURESHUTTERPOSITION', 'ETCHSOURCEUSAGE', 'ETCHAUXSOURCETIMER',\n",
      "       'ETCHAUX2SOURCETIMER', 'ACTUALSTEPDURATION',\n",
      "       'TTF_FlowCool Pressure Dropped Below Limit',\n",
      "       'TTF_Flowcool Pressure Too High Check Flowcool Pump',\n",
      "       'TTF_Flowcool leak'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_M02 = data_M02_train.merge(data_M02_ttf, left_on=\"time\", right_on=\"time\", how=\"left\")\n",
    "data_M02.drop_duplicates(inplace=True)\n",
    "\n",
    "print(len(data_M02_train), len(data_M02_ttf), len(data_M02))\n",
    "print(data_M02.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e730507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(66, 1443451), (67, 2716805), (68, 593630), (69, 218064), (70, 11731), (71, 40770), (72, 20474), (73, 33829), (74, 17062), (75, 1634), (76, 11793), (77, 1074)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "temp_list = data_M02[\"recipe\"].tolist()\n",
    "temp_list.sort()\n",
    "\n",
    "print(sorted(Counter(temp_list).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8624da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "9253-10511673\n"
     ]
    }
   ],
   "source": [
    "data_M02[\"Lot-runnum\"] = data_M02[\"Lot\"].apply(lambda x: str(x)) + \"-\" +\\\n",
    "data_M02[\"runnum\"].apply(lambda x: str(x))\n",
    "data_M02[\"recipe\"].apply(lambda x: int(np.around(x, decimals=0)))\n",
    "data_M02 = data_M02[data_M02[\"recipe\"] == 67]\n",
    "\n",
    "print(len(data_M02.loc[0, \"Lot-runnum\"]))\n",
    "print(data_M02.loc[0, \"Lot-runnum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb14f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1670/1670 [00:55<00:00, 30.16it/s]\n"
     ]
    }
   ],
   "source": [
    "data_grouped  = data_M02.groupby(data_M02[\"Lot-runnum\"])\n",
    "\n",
    "# print(data_grouped.get_group(\"9253_10511673\"))\n",
    "\n",
    "for group in tqdm(data_grouped.groups.keys()):    \n",
    "    data_export = data_grouped.get_group(group)\n",
    "    \n",
    "    # data M01\n",
    "#     data_export.to_csv(\"../phm_etching_01M01-02/M01_Groups/Lot_runnum_\" + str(group) + \".csv\",\n",
    "#                       index=None, encoding=\"utf8\")\n",
    "    \n",
    "    # data M02\n",
    "    data_export.to_csv(\"../phm_etching_01M01-02/M02_Groups_recipe_67/Lot_runnum_\" + str(group) + \".csv\",\n",
    "                      index=None, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bbc22",
   "metadata": {},
   "source": [
    "# Transform all data length to be same\n",
    "\n",
    "* Reference:\n",
    "  * https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html\n",
    "  * https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53fce3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e92ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1670/1670 [00:22<00:00, 72.83it/s]\n"
     ]
    }
   ],
   "source": [
    "length_list = []\n",
    "length_dict = {}\n",
    "\n",
    "# dir_path = \"../phm_etching_01M01-02/M01_Groups/\"\n",
    "dir_path = \"../phm_etching_01M01-02/M02_Groups_recipe_67/\"\n",
    "\n",
    "for file in tqdm(os.listdir(dir_path)):\n",
    "    data_temp = pd.read_csv(dir_path + file)\n",
    "    length_list.append(len(data_temp))\n",
    "    length_dict[file] = len(data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a453814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent length are: [1472, 1471, 1473, 1469, 1470]\n"
     ]
    }
   ],
   "source": [
    "# find data length with highest frequency\n",
    "# https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
    "\n",
    "counter_dict = collections.Counter(length_list)\n",
    "counter_dict =  dict(sorted(counter_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "most_frequent_length = list(counter_dict.keys())[0]\n",
    "print(\"The most frequent length are:\", list(counter_dict.keys())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e1113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in fault data for refactor\n",
    "\n",
    "# fault_data = \"../phm_etching_01M01-02/01_M01_train_fault_data.csv\"\n",
    "fault_data = \"../phm_etching_01M01-02/01_M02_train_fault_data.csv\"\n",
    "\n",
    "data_fault = pd.read_csv(fault_data,\n",
    "                        encoding=\"utf8\")\n",
    "\n",
    "fualt_time_list = data_fault.loc[:, \"time\"].tolist()\n",
    "fault_name_list = data_fault.loc[:, \"fault_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ea05e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1670it [02:24, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault Time not inside main training data: 79 [3915070, 3916822, 3918310, 3937494, 3940162, 3958954, 3968458, 8059958, 8105258, 8132488, 8136008, 9512452, 9518094, 12430304, 12435366, 12436028, 12437254, 12437984, 12439690, 12441326, 12514660, 12537920, 12580330, 12582892, 12588600, 12611078, 12619524, 12625938, 12635510, 12636486, 12649872, 12669900, 12681116, 12682450, 12684886, 12686968, 12688802, 12690282, 12692262, 12699926, 18057900, 18074648, 18097634, 18108796, 18139306, 18142434, 21905340, 22073942, 22075508, 22086924, 22779500, 22828180, 23082772, 23086028, 23087158, 23087648, 23348690, 23358554, 23630826, 23801808, 23834942, 25025806, 25637472, 28029182, 28113782, 28126778, 31427832, 35479832, 35672222, 36022710, 36132446, 36138198, 36145322, 36402870, 36575444, 36765886, 36767406, 36777452, 36797152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# starting interpolation and downsampling the data\n",
    "fault_time_inside_main_data = []\n",
    "\n",
    "# dir_path = \"../phm_etching_01M01-02/M01_Groups/\"\n",
    "# export_path = \"../phm_etching_01M01-02/M01_Groups_same_length/TotalFault_\"\n",
    "\n",
    "dir_path = \"../phm_etching_01M01-02/M02_Groups_recipe_67/\"\n",
    "export_path = \"../phm_etching_01M01-02/M02_Groups_recipe_67_same_length/TotalFault_\"\n",
    "\n",
    "\n",
    "for fileIndex, file in tqdm(enumerate(os.listdir(dir_path))):\n",
    "    situation_name = \"Healthy\"\n",
    "    total_fault = 0\n",
    "    \n",
    "#     if fileIndex == 1:\n",
    "#         fig, axs = plt.subplots(2, 1, figsize=(20, 5))\n",
    "#         axs[0].plot(data_temp.loc[:, \"recipe\"])\n",
    "#         axs[1].plot(data_export.loc[:, \"recipe\"])\n",
    "#         plt.show()\n",
    "#         break\n",
    "    \n",
    "    data_temp = pd.read_csv(dir_path + file)\n",
    "    \n",
    "    data_export = pd.DataFrame({\n",
    "        \"time\": signal.resample(data_temp.loc[:, \"time\"], num=most_frequent_length),\n",
    "        \"Tool\": [data_temp.loc[0, \"Tool\"] for i in range(most_frequent_length)],\n",
    "        \"Lot-runnum\": [data_temp.loc[0, \"Lot-runnum\"] for i in range(most_frequent_length)]\n",
    "    })\n",
    "    \n",
    "    # resampling for all columns\n",
    "    Lot_runnum = str(data_temp.loc[0, \"Lot-runnum\"])\n",
    "    for column in data_temp.columns:\n",
    "        if column in [\"time\", \"Tool\", \"Lot-runnum\"]:\n",
    "            continue\n",
    "        data_export[column] = signal.resample(data_temp.loc[:, column], num=most_frequent_length)\n",
    "        \n",
    "    # check which fault type is the data\n",
    "    for faultIndex, faultTime in enumerate(fualt_time_list):\n",
    "        if faultTime in data_temp.loc[:, \"time\"].tolist():\n",
    "            total_fault += 1\n",
    "            fault_time_inside_main_data.append(faultTime)\n",
    "            if situation_name == \"Healthy\":\n",
    "                situation_name = fault_name_list[faultIndex].replace(\" \", \"\")\n",
    "            else:\n",
    "                situation_name += (\"-\" + fault_name_list[faultIndex].replace(\" \", \"\"))\n",
    "            \n",
    "    data_export.to_csv(export_path + str(total_fault)\\\n",
    "                       + \"_\" + situation_name + \"_Lot_runnum_\" + Lot_runnum +\".csv\",\n",
    "                      index=None, encoding=\"utf8\")\n",
    "    \n",
    "temp = fualt_time_list.copy()\n",
    "for faultTime in fault_time_inside_main_data:\n",
    "    temp.remove(faultTime)\n",
    "    \n",
    "print(\"Fault Time not inside main training data:\", len(temp), temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
