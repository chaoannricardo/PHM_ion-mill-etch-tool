{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee07b776",
   "metadata": {},
   "source": [
    "# Tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab4ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a37f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "n_layers = 1\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49048ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "torch.Size([1, 1, 10]) torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# initialize hidden state of each cells\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "print(inp.shape)\n",
    "print(hidden_state.shape, cell_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe5a380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([1, 3, 10])\n",
      "Hidden:  (tensor([[[-8.4851e-02, -8.7748e-02,  6.2854e-02, -1.5089e-01,  7.9291e-05,\n",
      "           1.6117e-01,  1.5947e-01,  1.4106e-01,  1.1534e-01,  1.3942e-01]]],\n",
      "       grad_fn=<StackBackward>), tensor([[[-2.1368e-01, -1.8903e-01,  1.4674e-01, -3.4706e-01,  2.1826e-04,\n",
      "           3.3946e-01,  3.7381e-01,  2.4257e-01,  3.2680e-01,  2.7158e-01]]],\n",
      "       grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "# feed the input and hidden states and see what we’ll get back from it.\n",
    "out, hidden = lstm_layer(inp, hidden)\n",
    "\n",
    "print(\"Output shape: \", out.shape)\n",
    "print(\"Hidden: \", hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbf0a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the last output\n",
    "out = out.squeeze()[-1, :]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828f684",
   "metadata": {},
   "source": [
    "# Real implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cdad3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97735667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5013/5013 [00:38<00:00, 129.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5013, 1005, 21)\n",
      "(5013, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# TotalFault_5_FlowCoolPressureDroppedBelowLimit-Flowcoolleak-FlowCoolPressureDroppedBelowLimit-FlowCoolPressureDroppedBelowLimit-FlowCoolPressureDroppedBelowLimit_Lot_runnum_9295-10815254\n",
    "\n",
    "dir_path = \"../phm_etching_01M01-02/M02_Groups_same_length/\"\n",
    "shuffle_indexes = [i for i in range(len(os.listdir(dir_path)))]\n",
    "np.random.shuffle(shuffle_indexes)\n",
    "\n",
    "data_x = np.zeros((len(os.listdir(dir_path)), 1005, 21))\n",
    "data_y = pd.DataFrame({\n",
    "    \"Healthy\": [0 for i in range(len(os.listdir(dir_path)))],\n",
    "    \"FlowCoolPressureDroppedBelowLimit\": [0 for i in range(len(os.listdir(dir_path)))],\n",
    "    \"FlowcoolPressureTooHighCheckFlowcoolPump\": [0 for i in range(len(os.listdir(dir_path)))],\n",
    "    \"Flowcoolleak\": [0 for i in range(len(os.listdir(dir_path)))]\n",
    "})\n",
    "\n",
    "for fileIndex, file in enumerate(tqdm(os.listdir(dir_path))):\n",
    "    \n",
    "    fault_type_list = list(set(file.split(\"_\")[2].split(\"-\")))\n",
    "    lot_runnum = file.split(\"_\")[5].split(\".\")[0]\n",
    "    \n",
    "    data_import = pd.read_csv(dir_path + file, encoding=\"utf8\")\n",
    "    \n",
    "    data_import.drop(columns=['time', 'Tool', 'Lot', 'TTF_FlowCool Pressure Dropped Below Limit',\n",
    "       'TTF_Flowcool Pressure Too High Check Flowcool Pump', 'TTF_Flowcool leak', 'Lot-runnum'],\n",
    "                     inplace=True)\n",
    "    \n",
    "    data_x[shuffle_indexes[fileIndex]] = data_import.to_numpy()\n",
    "    \n",
    "    for faultType in [\"Healthy\", \"FlowCoolPressureDroppedBelowLimit\",\n",
    "                      \"FlowcoolPressureTooHighCheckFlowcoolPump\", \"Flowcoolleak\"]:\n",
    "        if faultType in fault_type_list:\n",
    "            data_y.loc[shuffle_indexes[fileIndex], faultType] = 1\n",
    "        \n",
    "data_y = data_y.to_numpy()\n",
    "        \n",
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dcbc2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split for training, validation, testing\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.2\n",
    "testing_ratio = 0.1\n",
    "\n",
    "train_indice = int(np.around(len(data_x) * training_ratio, 0))\n",
    "validation_indice = int(np.around(len(data_x) * training_ratio, 0)) +\\\n",
    "int(np.around(len(data_x) * validation_ratio, 0))\n",
    "\n",
    "x_train = data_x[:train_indice]\n",
    "y_train = data_y[:train_indice]\n",
    "x_validation = data_x[train_indice:validation_indice]\n",
    "y_validation = data_y[train_indice:validation_indice]\n",
    "x_test = data_x[validation_indice:]\n",
    "y_test = data_y[train_indice:validation_indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e44f6f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(is_cuda)\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06c31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d86cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
